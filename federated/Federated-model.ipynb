{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from scipy import stats\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\jad\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'Data/2016-2019(One station)/shair-8781-1-6-1.csv'\n",
    "airQualityData=pd.read_csv(dataPath, header=14,sep=';').rename(columns={'Start':'Start','Slut':'Stop'})\n",
    "airQualityData.rename(columns = lambda x: re.sub('NOX.*','NOX',x), inplace = True)\n",
    "airQualityData.rename(columns = lambda x: re.sub('PM10.*','PM10',x), inplace = True)\n",
    "airQualityData.rename(columns = lambda x: re.sub('PM2.5.*','PM2_5',x), inplace = True)\n",
    "airQualityData.rename(columns = lambda x: re.sub('NO2.*','NO2',x), inplace = True)\n",
    "airQualityData.rename(columns = lambda x: re.sub('O3.*','O3',x), inplace = True)\n",
    "airQualityData.rename(columns = lambda x: re.sub('Black Carbon.*','Black Carbon',x), inplace = True)\n",
    "airQualityData['Start'] = pd.to_datetime(airQualityData['Start'])\n",
    "airQualityData= airQualityData.drop('Stop',axis=1)\n",
    "one_feature=airQualityData.drop(columns=['Black Carbon','O3','PM2_5'])#\n",
    "one_feature.head(5)\n",
    "one_feature = one_feature.fillna(0)\n",
    "# one_feature = one_feature.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "scaled_down=one_feature.copy()\n",
    "scaled_down['PM10']=sc.fit_transform(scaled_down['PM10'].values.reshape(-1, 1))\n",
    "scaled_down['NOX']=sc.fit_transform(scaled_down['NOX'].values.reshape(-1, 1))\n",
    "scaled_down['NO2']=sc.fit_transform(scaled_down['NO2'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=scaled_down[(scaled_down['Start']<= \"2018-12-31 23:00:00\")]\n",
    "test=scaled_down[(scaled_down['Start'] >= \"2019-01-01 00:00:00\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jad\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>PM10</th>\n",
       "      <th>predicted_pollution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039648</td>\n",
       "      <td>0.009583</td>\n",
       "      <td>0.189614</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027313</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.070652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018502</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.081522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.091184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.091184</td>\n",
       "      <td>0.094807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NO2       NOX      PM10  predicted_pollution\n",
       "0  0.039648  0.009583  0.189614             0.069444\n",
       "1  0.027313  0.005719  0.069444             0.070652\n",
       "2  0.018502  0.004482  0.070652             0.081522\n",
       "3  0.014097  0.003400  0.081522             0.091184\n",
       "4  0.012335  0.003246  0.091184             0.094807"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['predicted_pollution'] = train['PM10'].shift(-1)\n",
    "\n",
    "# Drop the last row (it has no value for predicted pollution)\n",
    "train = train.drop(train.tail(1).index)\n",
    "train=train.drop('Start',axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jad\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOX</th>\n",
       "      <th>PM10</th>\n",
       "      <th>predicted_pollution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.243357</td>\n",
       "      <td>0.102053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>0.038767</td>\n",
       "      <td>0.007883</td>\n",
       "      <td>0.102053</td>\n",
       "      <td>0.051329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35066</th>\n",
       "      <td>0.030837</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.051329</td>\n",
       "      <td>0.039855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>0.014097</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.039855</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35068</th>\n",
       "      <td>0.021145</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.052536</td>\n",
       "      <td>0.044082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NO2       NOX      PM10  predicted_pollution\n",
       "35064  0.041410  0.008501  0.243357             0.102053\n",
       "35065  0.038767  0.007883  0.102053             0.051329\n",
       "35066  0.030837  0.006337  0.051329             0.039855\n",
       "35067  0.014097  0.003246  0.039855             0.052536\n",
       "35068  0.021145  0.004946  0.052536             0.044082"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted_pollution'] = test['PM10'].shift(-1)\n",
    "\n",
    "# Drop the last row (it has no value for predicted pollution)\n",
    "test = test.drop(test.tail(1).index)\n",
    "test=test.drop('Start',axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values=train.values\n",
    "test_values=test.values\n",
    "test_X, test_y = test_values[:, :-1], test_values[:, -1]\n",
    "train_X, train_y = train_values[:, :-1], train_values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER = 10\n",
    "\n",
    "def preprocess(dataset):\n",
    "\n",
    "  def batch_format_fn(element):\n",
    "      return collections.OrderedDict(x=element['x'], y=element['y'])\n",
    "\n",
    "  return dataset.batch(\n",
    "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
    "\n",
    "# produce datasets for each origin\n",
    "def make_federated_data(X_train, y_train, X_test, y_test):\n",
    "        train_datasets = []\n",
    "        test_datasets = []\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({'x': X_train, 'y': y_train}))\n",
    "        \n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            ({'x': X_test, 'y': y_test}))\n",
    "\n",
    "        preprocessed_train_dataset = preprocess(train_dataset)\n",
    "        preprocessed_test_dataset = preprocess(test_dataset)\n",
    "\n",
    "        train_datasets.append(preprocessed_train_dataset)\n",
    "        test_datasets.append(preprocessed_test_dataset)\n",
    "        \n",
    "        return train_datasets, test_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets, test_datasets = make_federated_data(train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tff_model():\n",
    "  return tff.learning.from_keras_model(build_model(), \n",
    "                                       input_spec=train_datasets[0].element_spec,\n",
    "                                       loss=tf.keras.losses.MeanSquaredError(),\n",
    "                                       metrics=[tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create averaging process\n"
     ]
    }
   ],
   "source": [
    "print(\"Create averaging process\")\n",
    "iterative_process = tff.learning.build_federated_averaging_process(model_fn=create_tff_model,\n",
    "                                                                   client_optimizer_fn = lambda: tf.keras.optimizers.SGD(0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initzialize averaging process\n",
      "Start iterations\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0036236446), ('loss', 0.0036251866)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0030450574), ('loss', 0.003046321)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0030251974), ('loss', 0.0030264535)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0030056585), ('loss', 0.0030069053)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0029863922), ('loss', 0.0029876374)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0029674026), ('loss', 0.0029686356)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0029486695), ('loss', 0.0029498981)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0029301916), ('loss', 0.0029314188)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.002911964), ('loss', 0.0029131817)]))])\n",
      "metrics=OrderedDict([('broadcast', ()), ('aggregation', ()), ('train', OrderedDict([('mean_squared_error', 0.0028939738), ('loss', 0.0028951883)]))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initzialize averaging process\")\n",
    "state = iterative_process.initialize()\n",
    "\n",
    "print(\"Start iterations\")\n",
    "for _ in range(10):\n",
    "  state, metrics = iterative_process.next(state, train_datasets)\n",
    "  print('metrics={}'.format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mean_squared_error', 0.003661314), ('loss', 0.0036615871)])\n"
     ]
    }
   ],
   "source": [
    "# Global model evaluated over all clients\n",
    "evaluation = tff.learning.build_federated_evaluation(model_fn=create_tff_model)\n",
    "test_metrics = evaluation(state.model, test_datasets)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('mean_squared_error', 0.003661314), ('loss', 0.0036615871)])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_datasets)):\n",
    "    test_metrics = evaluation(state.model, [test_datasets[i]])\n",
    "    print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('x',\n",
       "              TensorSpec(shape=(None, 1, 3), dtype=tf.float64, name=None)),\n",
       "             ('y', TensorSpec(shape=(None,), dtype=tf.float64, name=None))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0].element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PrefetchDataset shapes: OrderedDict([(x, (None, 1, 3)), (y, (None,))]), types: OrderedDict([(x, tf.float64), (y, tf.float64)])>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
